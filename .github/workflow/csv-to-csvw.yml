name: Generate CSV-W from csv upload to repository.

on:
  push:
    branches:
      - main

jobs:
  generate_csvw_from_csv_upload:
    name: Generate CSV-W from csv upload
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Install csvcubed
        run: pip install csvcubed

      - name: Verify csvcubed installation
        run: csvcubed version

      - name: Check out repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: View working directory
        run: ls -la $GITHUB_WORKSPACE

      - name: Configure git
        run: |
          git config --global user.name "CSV-W from csv upload generator"
          git pull

      - name: Get all added/changed/removed files inside csv folder
        id: get-added-changed-removed-files
        uses: jitterbit/get-changed-files@v1
        with:
          format: "csv"

      - name: Process all added/changed files inside csv folder
        id: process-added-changed-files
        run: |
          echo "::set-output name=has_outputs::${{ toJSON(false) }}"
          mapfile -d ',' -t added_modified_files < <(printf '%s,' '${{ steps.get-added-changed-removed-files.outputs.added_modified }}')

          for file in "${added_modified_files[@]}"; do
            echo "${file}"
            file_path="${file%.*}"
            file_name="${file_path##*/}"
            file_extension="${file##*.}"
            out_path="out/${file_path}/"
            
            echo "file_path: ${file_path}"
            echo "file_name: ${file_name}"
            echo "file_extension: ${file_extension}"
            echo "out_path: ${out_path}"

            if [[ $file_extension == "csv" ]]; then
              echo $'\n'
              echo "Processing file ${file}"
              echo "Output path is ${out_path}"

              csv_file=${file}
              for file_secondary in "${added_modified_files[@]}"; do
                file_secondary_name="${file_secondary%.*}"
                file_secondary_extension="${file_secondary##*.}"
                if [[ "${file_secondary_name}.${file_secondary_extension}" == "${file_path}.json" ]]; then
                  config_file="${file_secondary_name}.json"
                fi
              done
              
              if [[ -f $config_file ]]; then
                echo "Config for ${csv_file} is available: ${config_file}"
                echo "Building CSV-W"
                csvcubed build $csv_file -c $config_file --out $out_path --validation-errors-to-file
              else
                echo "Config for ${csv_file} is not available"
                echo "Building CSV-W"
                csvcubed build $csv_file --out $out_path --validation-errors-to-file
              fi
              
              echo "Inspecting CSV-W"
              inspect_output_file="${out_path}inspect_output.txt"
              if [[ -f $inspect_output_file ]]; then
                  rm $inspect_output_file
              fi

              mapfile -d $'\0' inspectable_files < <(find "${GITHUB_WORKSPACE}/${out_path}" -name "*.csv-metadata.json" -type f -print0)
              for file in "${inspectable_files[@]}"; do
                echo "Inspecting file ${file}"
                csvcubed inspect $file >> "${out_path}inspect_output.txt"
              done
              

              unset $config_file
              echo "Finished processing file ${file}"
              echo "::set-output name=has_outputs::${{ toJSON(true) }}"
            fi
          done

      - name: Process all removed files inside csv folder
        id: process-removed-files
        run: |
          echo "::set-output name=has_outputs::${{ toJSON(false) }}"
          mapfile -d ',' -t removed_files < <(printf '%s,' '${{ steps.get-added-changed-removed-files.outputs.removed }}')
          for file in "${removed_files[@]}"; do
            file_path="${file%.*}"
            file_name="${file_path##*/}"
            file_extension="${file##*.}"

            if [[ $file_extension == "csv" && "${file_path}" != *"out/"* ]]; then
                echo $'\n'
                echo "Handling deletions for file ${file}"
                config_file="${file_path}.${file_extension}.json"
                out_folder="out/${file_path}/"
                
                if [[ -f $config_file ]]; then
                  git rm $config_file
                  git commit -m "Deleted out folder for file ${file} - $(date +'%d-%m-%Y at %H:%M:%S')"
                fi

                if [[ -d $out_folder ]]; then
                  git rm -r $out_folder
                  git commit -m "Deleted out folder for file ${file} - $(date +'%d-%m-%Y at %H:%M:%S')"
                fi
                
                git push
                
                echo "Finished handling deletions for file ${file}"
                echo "::set-output name=has_outputs::${{ toJSON(true) }}"
            fi
          done

      - name: Commit generated CSV-Ws and logs to the repository
        if: ${{ fromJSON(steps.process-added-changed-files.outputs.has_outputs) == true }}
        run: |
          echo $'\nCommitting CSV-Ws\n'
          git add out/
          git commit -m "CSV-Ws generated from csv upload - $(date +'%d-%m-%Y at %H:%M:%S')"
          git push

      - name: Publish CSV-Ws and logs to artefacts
        if: ${{ fromJSON(steps.process-added-changed-files.outputs.has_outputs) == true }}
        uses: actions/upload-artifact@v2
        with:
          name: assets-for-download
          path: out

      - name: Publish CSV-Ws and logs to GitHub Pages
        if: ${{ fromJSON(steps.process-added-changed-files.outputs.has_outputs) == true }}
        run: |
          echo $'\n'
          echo "Publishing to GitHub Pages"
          git checkout -b gh-pages
          rm -r LICENSE
          rm -r README.md
          rm -r .github/workflows

          repo_name=${GITHUB_REPOSITORY#*/}    
          username=${GITHUB_REPOSITORY_OWNER}
          commit_id=${GITHUB_SHA}      
          mapfile -d ',' -t out_files < <(printf '%s,' $(find . -type f -path '*out/*'))
          processed_out_files=$(printf ",%s" "${out_files[@]}")

          touch .nojekyll
          touch index.html

          cat > index.html <<EOL
          <!doctype html>
          <html>
            <head>
            </head>
            <body>
              <h3>CSV-Ws generated are as below. The latest commit id is ${commit_id}.</h3>
              <div id="files-container"></div>
              <script type="text/javascript">
                var html_str = "<ul>";
                var files = "${processed_out_files}".split(',');
                files.shift()
                files.sort()
                files.forEach(function(file) {
                  file = file.replace("./","")
                  link = "https://${username}.github.io/${repo_name}/"+file
                  html_str += "<li>"+"<a href='"+ link + "'>"+file+"</a></li>";
                });
                html_str += "</ul>";
                document.getElementById("files-container").innerHTML = html_str;
              </script>
            </body>
          </html>
          EOL

          git add .nojekyll
          git add index.html
          git commit -a -m "Updating outputs in GitHub Pages - $(date +'%d-%m-%Y at %H:%M:%S')"
          git push --set-upstream origin gh-pages -f
